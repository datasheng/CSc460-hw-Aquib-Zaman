{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## # Introduction\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n",
    "<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n",
    "<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n",
    "<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n",
    "<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Task 1: Import libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m                  \u001b[38;5;66;03m# To get objects from the web\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m                      \u001b[38;5;66;03m# To manipulate text data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup    \u001b[38;5;66;03m# To manipulate HTML code\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter  \u001b[38;5;66;03m# To count words\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "### Task 1: Import libraries\n",
    "import requests                  # To get objects from the web\n",
    "import nltk                      # To manipulate text data\n",
    "from bs4 import BeautifulSoup    # To manipulate HTML code\n",
    "from collections import Counter  # To count words\n",
    "\n",
    "### Task 2: Get HTML\n",
    "# Request HTML response from website\n",
    "r = requests.get(\"https://www.gutenberg.org/files/16/16-h/16-h.htm\")\n",
    "\n",
    "# Set the response encoding to utf-8\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "# Get HTML code from response\n",
    "html = r.text\n",
    "\n",
    "### Task 3: Get text\n",
    "# Convert to Unicode\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# Extract text\n",
    "text = soup.text\n",
    "\n",
    "### Task 4: Get words\n",
    "# Create tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(\"\\w+\")\n",
    "\n",
    "# Tokenize text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "### Task 5: Lowercase\n",
    "# Lowercase tokens\n",
    "words = [token.lower() for token in tokens]\n",
    "\n",
    "### Task 6: Load stopwords\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Make a list of stop words\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "### Task 7: Remove stopwords\n",
    "# Remove stopwords from tokens list\n",
    "words_clean = [word for word in words if word not in stop_words]\n",
    "\n",
    "### Task 8: Count words\n",
    "# Get count dictionary\n",
    "count = Counter(words_clean)\n",
    "\n",
    "# Get top 10 most common words\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "### Task 9: Declare protagonists\n",
    "protagonists = [\"hook\", \"john\", \"peter\", \"wendy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
